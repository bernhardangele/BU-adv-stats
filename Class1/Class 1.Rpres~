Advanced Statistics
========================================================
author: Bernhard Angele 
date: October 2nd, 2014

What is advanced about these statistics?
========================================================

- Goal is for you to understand the principles, not just the steps.
- Simulation approach:
  - If you don't know how something about a statistical test, simulate it!
  - Example questions you might ask:
    - What is the power of this test?
    - What happens if I violate the normality assumption for an ANOVA?
    - What happens if I don't correct for multiple comparisons?
  

How do I run simulations?
========================================================

- Not very easy in SPSS
- Very easy in R


R basics
========================================================
Addition
```{r}
1+1
```
Subtraction
```{r}
1-1
```

R basics
========================================================
Multiplication and division
```{r}
4*3
12/4
```

R basics
========================================================
Powers
```{r}
5^2
2^3
```

Variables
========================================================
```{r}
x <- 5
x + 1
```


Commands
========================================================
```{r}
x <- 5
x + 1
x
```
Is anyone surprised by this?

Functions
========================================================
```{r}
addOne <- function(x) {
  x+1
}
addOne(5)
addOne(-3)
```

Types of data
========================================================
```{r}
x <- 1
y <- "test"
z <- c(1,2)
z
```
z is a **vector**
```{r}
z + 1
```

Vector operations
========================================================
```{r}
z <- c(1,2,3,4,5)
z + 2
z - 1
z * 2
```

More vector operations
========================================================
```{r}
z <- c(1,2,3,4,5)
sum(z)
length(z)
sum(z)/length(z)
```

Descriptive statistics
========================================================
We could define a new function that calculates the mean.
But maybe it's defined for us already?
```{r}
z <- c(1,2,3,4,5)
mean(z)
```

What about other descriptive statistics?
========================================================
```{r}
median(z)
sd(z)
var(z)
```

Summary: lots of interesting descriptive statistics at once
========================================================
```{r}
summary(z)
```


Let's simulate some data
========================================================

```{r}
x<-rnorm(1000)
head(x)
plot(x)
```

Distribution of the simulated data (histogram)
========================================================

```{r, echo=T, fig.width = 14, fig.height = 6}
## plot density histogram:
par(mfrow=c(1,2)) # (little trick: two plots side-by-side)
hist(x,freq=F)
plot(density(x))
```

Probability density?
========================================================
```{r, echo=T, fig.width = 10, fig.height = 6}
plot(function(x) dnorm(x), -3, 3,
main = "Normal density",ylim=c(0,.4),
ylab="density",xlab="X")
```

Normal probability density function (PDF)
========================================================
$$
\begin{equation}
  f(x,\mu,\sigma) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-((x - \mu)^2/2 \sigma^2)}
\end{equation}
$$
With $x$ = value, 
$\mu$ = mean, 
and $\sigma$ = standard deviation
```{r, echo=F, fig.width = 10, fig.height = 6}
plot(function(x) dnorm(x), -3, 3,
main = "Normal density",ylim=c(0,.4),
ylab="density",xlab="X")
```

Defining the normal PDF by hand (just in case you wanted to make sure)
========================================================
$$
\begin{equation}
  f(x,\mu,\sigma) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-((x - \mu)^2/2 \sigma^2)}
\end{equation}
$$
```{rfig.width = 10, fig.height = 6}
dnorm_manual <- function(x, mu = 0, sigma = 1) {1/(sigma*sqrt(2*pi)) * exp(-((x-mu)^2/2*sigma^2))}
plot(function(x) dnorm_manual(x), -3, 3,
main = "Normal density",ylim=c(0,.4),
ylab="density",xlab="X")
```

Why do we care about the normal distribution?
========================================================
- Central limit theorem (CLT)

> When sampling from a population that has a mean, provided the sample size is large
> enough, the sampling distribution of the sample mean will be close to normal regardless
> of the shape of the population distribution

Let's see if that's actually true by running some simulations!

Non-normal distributions: Uniform
========================================================

```{r, echo=T, fig.width = 14, fig.height = 6}
## plot density histogram:
x <- runif(n = 1000)
par(mfrow=c(1,2)) # (two plots side-by-side)
hist(x,freq=F)
plot(density(x))
```


Non-normal distributions: Gamma
========================================================

```{r, echo=T, fig.width = 14, fig.height = 6}
## plot density histogram:
x<-rgamma(n = 1000, shape = 2)
par(mfrow=c(1,2)) # (two plots side-by-side)
hist(x,freq=F)
plot(density(x))
```


Sampling from a gamma distribution (1)
========================================================

```{r, echo=T, fig.width = 14, fig.height = 6}
number_of_simulations <- 100000

sample_mean_from_gamma <- function(number_of_samples){
  samples <- rgamma(number_of_samples, shape = 2)
  mean(samples)
}

sample_means <- sapply(1:number_of_simulations, sample_mean_from_gamma)
summary(sample_means)
```

Sampling from a gamma distribution (2)
========================================================

```{r, echo=T, fig.width = 14, fig.height = 6}
par(mfrow=c(1,2)) # (two plots side-by-side)
hist(sample_means,freq=F)
plot(density(sample_means))
```

Sampling from au uniform distribution (1)
========================================================

```{r, echo=T, fig.width = 14, fig.height = 6}
number_of_simulations <- 100

sample_mean_from_gamma <- function(number_of_samples){
  samples <- runf(number_of_samples, shape = 2)
  mean(samples)
}

sample_means <- sapply(1:number_of_simulations, sample_mean_from_gamma)
summary(sample_means)
```

Sampling from a uniform distribution (2)
========================================================

```{r, echo=T, fig.width = 14, fig.height = 6}
par(mfrow=c(1,2)) # (two plots side-by-side)
hist(sample_means,freq=F)
plot(density(sample_means))
```
